name: "convNet"

layer {
	name: "mnist"
	type: "Data"

	top: "data"
	top: "label"
	data_param {
		source: "data/mnist_train_lmdb"
		backend: LMDB
		batch_size: 120
	}
	transform_param {
		scale: 0.00390625		#1/256, compress the input values to [0, 1)
	}
	include {
		phase: TRAIN
	}
}

layer {
        name: "mnist"
        type: "Data"

        top: "data"
        top: "label"
        data_param {
                source: "data/mnist_test_lmdb"
                backend: LMDB
                batch_size: 100
        }
        transform_param {
                scale: 0.00390625               #1/256, compress the input values to [0, 1)
        }
        include {
                phase: TEST
        }
}


#=========== conv ============
layer {
	name: "conv1"
	type: "Convolution"
	bottom: "data"
	top: "conv1"
	convolution_param {
		num_output: 64
		kernel_size: 5
		pad: 2
		weight_filler {
			type: "xavier"
		}
	}
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
}

layer {
	name: "relu1"
	type: "ReLU"
	bottom: "conv1"
	top: "conv1"
	relu_param {
		negative_slope: 0.1
	}
}

layer {
	name: "pool1"
	type: "Pooling"
	bottom: "conv1"
	top: "pool1"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride: 2
	}
}

layer {
	name: "conv2"
	type: "Convolution"
	bottom: "pool1"
	top: "conv2"
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
	}
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
}

layer {
	name: "relu2"
	type: "ReLU"
	bottom: "conv2"
	top: "conv2"
	relu_param {
		negative_slope: 0.1
	}
}

layer {
	name: "pool2"
	type: "Pooling"
	bottom: "conv2"
	top: "pool2"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride: 2
	}
}

layer {
	name: "ip1"
	type: "InnerProduct"
	bottom: "pool2"
	top: "ip1"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	inner_product_param {
		num_output: 100
		weight_filler {
			type: "xavier"
		}
	}
}

layer {
	name: "dropout"
	type: "Dropout"
	bottom: "ip1"
	top: "ip1"
	dropout_param {
		dropout_ratio: 0.5
	}
}

layer {
	name: "ip2"
	type: "InnerProduct"
	bottom: "ip1"
	top: "ip2"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	inner_product_param {
		num_output: 10
		weight_filler {
			type: "xavier"
		}
	}
}


#=========== loss ===========
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}


layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "ip2"
	bottom: "label"
}

